Importing candle utils for keras
Configuration file:  /gpfs/mira-home/apeck/Modified_Benchmarks/Pilot1/P1B1/p1b1_default_model.txt
{'activation': 'relu',
 'alpha_dropout': False,
 'base_lr': None,
 'batch_normalization': False,
 'batch_size': 100,
 'dense': [2000, 600],
 'drop': 0,
 'epochs': 100,
 'epsilon_std': 1.0,
 'feature_subsample': 0,
 'file_test': 'P1B1.dev.test.csv',
 'file_train': 'P1B1.dev.train.csv',
 'initialization': 'glorot_uniform',
 'latent_dim': 2,
 'learning_rate': None,
 'loss': 'mse',
 'model': 'ae',
 'model_name': 'p1b1',
 'noise_factor': 0,
 'optimizer': 'adam',
 'rng_seed': 2017,
 'save_path': 'save',
 'scaling': 'minmax',
 'solr_root': '',
 'timeout': 3600,
 'url_p1b1': 'http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/',
 'validation_split': 0.1}
Params:
{'activation': 'relu',
 'alpha_dropout': False,
 'base_lr': None,
 'batch_normalization': False,
 'batch_size': 100,
 'cp': False,
 'datatype': <class 'numpy.float32'>,
 'dense': [2000, 600],
 'drop': 0,
 'epochs': 100,
 'epsilon_std': 1.0,
 'experiment_id': 'EXP000',
 'feature_subsample': 0,
 'file_test': 'P1B1.dev.test.csv',
 'file_train': 'P1B1.dev.train.csv',
 'gpus': [],
 'initialization': 'glorot_uniform',
 'latent_dim': 2,
 'learning_rate': None,
 'logfile': None,
 'loss': 'mse',
 'model': 'ae',
 'model_name': 'p1b1',
 'noise_factor': 0,
 'optimizer': 'adam',
 'output_dir': '/gpfs/mira-home/apeck/CANDLE_testing/avery_modified_results/run4/Output/EXP000/RUN000',
 'reduce_lr': False,
 'residual': False,
 'rng_seed': 2017,
 'run_id': 'RUN000',
 'save_path': 'save',
 'scaling': 'minmax',
 'shuffle': False,
 'solr_root': '',
 'tb': False,
 'timeout': 3600,
 'train_bool': True,
 'tsne': False,
 'url_p1b1': 'http://ftp.mcs.anl.gov/pub/candle/public/benchmarks/P1B1/',
 'use_landmark_genes': False,
 'validation_split': 0.1,
 'verbose': None,
 'warmup_lr': False}
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 60483)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 2000)              120968000 
_________________________________________________________________
dense_2 (Dense)              (None, 600)               1200600   
_________________________________________________________________
dense_3 (Dense)              (None, 2)                 1202      
_________________________________________________________________
model_2 (Model)              (None, 60483)             122230283 
=================================================================
Total params: 244,400,085
Trainable params: 244,400,085
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 2)                 0         
_________________________________________________________________
dense_4 (Dense)              (None, 600)               1800      
_________________________________________________________________
dense_5 (Dense)              (None, 2000)              1202000   
_________________________________________________________________
dense_6 (Dense)              (None, 60483)             121026483 
=================================================================
Total params: 122,230,283
Trainable params: 122,230,283
Non-trainable params: 0
_________________________________________________________________
Train on 2700 samples, validate on 300 samples
Epoch 1/100
 - 298s - loss: 0.1326 - xent: 0.6902 - corr: 12.8341 - val_loss: 0.1302 - val_xent: 0.6836 - val_corr: 0.7154
Current time ....297.929
Epoch 2/100
 - 277s - loss: 0.0912 - xent: 0.6012 - corr: 0.7775 - val_loss: 0.0484 - val_xent: 0.4910 - val_corr: 0.7308
Current time ....574.967
Epoch 3/100
 - 278s - loss: 0.0399 - xent: 0.4672 - corr: 0.7787 - val_loss: 0.0477 - val_xent: 0.4895 - val_corr: 0.7369
Current time ....852.915
Epoch 4/100
 - 289s - loss: 0.0385 - xent: 0.4605 - corr: 0.7851 - val_loss: 0.0469 - val_xent: 0.4837 - val_corr: 0.7407
